name: Unit Tests

run-name: "${{ github.event.inputs.title }}"

defaults:
  run:
    shell: bash -le {0}

on:
  repository_dispatch:
  workflow_dispatch:
    inputs:
      title:
        description: 'set a title for this run'
        required: false
        default: ''
      repo:
        description: 'GitHub repo {owner}/{repo}'
        required: false
        default: ''
      ref:
        description: 'GitHub ref: Branch, Tag or Commit SHA'
        required: false
        default: ''
      pr_number:
        description: 'PR Number'
        required: false
        type: number
      test_names:
        description: 'Input Test(s) to Run (default all)'
        required: false
        default: ''
      test_regex:
        description: 'Regex to filter test files'
        required: false
        default: ''
      artifact_id:
        description: 'Run id for artifact to be downloaded'
        required: false
        default: ''
      max-parallel:
        description: 'Parallel jobs'
        required: false
        default: '10'
      exclusive-gpu:
        description: 'One Test Per GPU'
        type: boolean
        required: false
        default: true
      server:
        description: 'Wheel Build Server'
        type: choice
        default: '["self-hosted", "xeon5"]'
        options:
          - '["self-hosted", "xeon5"]'
          - '["self-hosted", "zen4"]'

env:
  CUDA_DEVICE_ORDER: PCI_BUS_ID
  CUDA_VISIBLE_DEVICES: 0
  TORCH_CUDA_ARCH_LIST: '8.6 8.9 9.0 12.0'
  PYTORCH_ALLOC_CONF: 'expandable_segments:True'
  MAX_JOBS: 12 # compile concurrency
  RUNNER: 10.0.13.31
  XEON5: 10.0.14.249
  UV_INDEX_URL: http://10.0.14.249/simple
  CUDA_VERSION: 128
  TORCH_VERSION: 2.8.0
  PYTHON_VERSION: 3.12 # use 312, no need to recompile libs like flash_attn...
  UV_PYTHON: python3.12
  # PYTHON_GIL: 0 // test libs don't support yet
  BUILD_QQQ: 1
  BUILD_EORA: 1
  GPTQMODEL_BUILD_EXLLAMA_V1: 1
  GPTQMODEL_BUILD_EORA: 1
  IGNORED_TEST_FILES: "test_tgi.py,test_gptneox.py,models/test_mixtral.py,models/test_phi_3_moe.py,test_bits_new.py,models/test_internlm.py,models/test_internlm2_5.py,models/test_xverse.py"
  GPTQMODEL_FORCE_BUILD: 1
  repo: ${{ github.event.inputs.repo || github.repository }}
  ref: ${{ github.event.inputs.ref || github.ref }}

concurrency:
  group: ${{ github.event.inputs.ref || github.ref }}-workflow-unit-tests-${{ github.event.inputs.test_names }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  check-vm:
    runs-on: ubuntu-24.04
    outputs:
      ip: ${{ steps.get_ip.outputs.ip }}
      run_id: ${{ steps.get_ip.outputs.run_id }}
      max-parallel: ${{ steps.get_ip.outputs['max-parallel'] }}
      cuda_version: ${{ env.CUDA_VERSION }}
    steps:
      - name: Print env
        run: |
          echo "repo: ${{ env.repo }}"
          echo "ref: ${{ env.ref }}"
          echo "artifact_id: ${{ github.event.inputs.artifact_id }}"
          echo "test_names: ${{ github.event.inputs.test_names }}"
          echo "exclusive-gpu: ${{ github.event.inputs['exclusive-gpu'] }}"
          echo "selected server: ${{ github.event.inputs.server }}"

      - name: Select server
        id: get_ip
        run: |
          echo "ip=$RUNNER" >> "$GITHUB_OUTPUT"

          echo "ip: $ip"

          if [ -n "${{ github.event.inputs.artifact_id }}" ]; then
            run_id="${{ github.event.inputs.artifact_id }}"
          else
            run_id="${{ github.run_id }}"
          fi
          echo "run_id=$run_id" >> "$GITHUB_OUTPUT"
          echo "artifact_id=$run_id"

          max_p=${{ github.event.inputs['max-parallel'] }}
          max_p="{\"size\": ${max_p:-20}}"
          echo "max-parallel=$max_p" >> "$GITHUB_OUTPUT"
          echo "max-parallel=$max_p"

  list-test-files:
    runs-on: ubuntu-24.04
    outputs:
      torch-files: ${{ steps.files.outputs.torch-files }}
      m4-files: ${{ steps.files.outputs.m4-files }}

    steps:
      - name: Checkout Codes
        uses: actions/checkout@v6
        with:
          repository: ${{ env.repo }}
          ref: ${{ env.ref }}

      - name: Fetch PR by number
        if: ${{ github.event.inputs.pr_number != 0 }}
        run: |
          PR_NUMBER=${{ github.event.inputs.pr_number }}
          echo "pr number $PR_NUMBER"
          git config --global --add safe.directory $(pwd)
          git fetch origin pull/${PR_NUMBER}/head:pr-${PR_NUMBER}
          git checkout pr-${PR_NUMBER}

      - name: List files
        id: files
        run: |
          test_files=$(python3 .github/scripts/list_test_files.py \
          --ignored-test-files "$IGNORED_TEST_FILES" \
          --test-names "${{ github.event.inputs.test_names }}" \
          --test-regex "${{ github.event.inputs.test_regex }}")

          IFS='|' read -r torch_test_files mlx_files <<< "$test_files"

          echo "torch-files=$torch_test_files" >> "$GITHUB_OUTPUT"
          echo "m4-files=$mlx_files" >> "$GITHUB_OUTPUT"

          echo "Test files: $test_files"
          echo "Torch Test files: $torch_test_files"
          echo "MLX Test files: $mlx_files"
          echo "Ignored Test files: $IGNORED_TEST_FILES"

  build:
    runs-on: ${{ fromJSON(github.event.inputs.server || '["self-hosted", "xeon5"]') }}
    needs:
      - check-vm
      - list-test-files
    if: needs.list-test-files.outputs.torch-files != '[]'
    container:
      image: ${{ needs.check-vm.outputs.ip }}:5000/nvidia/cuda:${{ needs.check-vm.outputs.cuda_version }}-ubuntu22.04_0206
      options: --device /dev/dri --ipc=host --runtime=nvidia --gpus all
      volumes:
        - /monster/ci/env/entrypoint.sh:/entrypoint.sh
        - /monster/ci/env/entrypoint.sh:/etc/profile.d/01-entrypoint.sh
        - /dev/dri/by-path:/dev/dri/by-path
        - /monster/ci/models:/monster/data/model
        - /monster/ci/dataset:/monster/data/model/dataset
        - /monster/ci/huggingface:/github/home/.cache/huggingface
        - /monster/ci/uv:/opt/uv
        - /monster/ci/env:/opt/env
        - /monster/ci/dist:/opt/dist

    steps:
      - name: Checkout Codes
        uses: actions/checkout@v6
        with:
          repository: ${{ env.repo }}
          ref: ${{ env.ref }}

      - name: Fetch PR by number
        if: ${{ github.event.inputs.pr_number != 0 }}
        run: |
          PR_NUMBER=${{ github.event.inputs.pr_number }}
          echo "pr number $PR_NUMBER"
          git config --global --add safe.directory $(pwd)
          git fetch origin pull/${PR_NUMBER}/head:pr-${PR_NUMBER}
          git checkout pr-${PR_NUMBER}

      - name: Print env
        run: |
          echo PATH=$PATH
          echo UV_INSTALL_DIR=$UV_INSTALL_DIR
          echo UV_PYTHON_BIN_DIR=$UV_PYTHON_BIN_DIR
          echo UV_PYTHON_INSTALL_DIR=$UV_PYTHON_INSTALL_DIR
          echo UV_PYTHON_CACHE_DIR=$UV_PYTHON_CACHE_DIR
          echo UV_CACHE_DIR=$UV_CACHE_DIR
          echo VENV_ROOT=$VENV_ROOT
          ls /root -ahl

      - name: Activate uv env
        run: |
          env_name="cu${{ needs.check-vm.outputs.cuda_version }}_torch${{ env.TORCH_VERSION }}_py${{ env.PYTHON_VERSION }}_build"
          /opt/uv/setup_uv_venv.sh $env_name

      - name: Setup uv env
        run: |
          bash /opt/env/init_compiler_torch_only.sh ${{ needs.check-vm.outputs.cuda_version }} ${{ env.TORCH_VERSION }} ${{ env.PYTHON_VERSION }}
          
          echo "::group::uv python list"
          uv python list
          ls -ahl /opt/uv/venvs
          echo "::endgroup::"
          
          echo "== python =="
          python --version
          which python
          which pip || true

          echo "== nvcc =="
          nvcc --version

          echo "::group::pip list"
          uv pip list
          echo "::endgroup::"

          echo "== torch =="
          uv pip show torch || true

      - name: Compress dir
        run: |
          mkdir dist || true
          rm -rf dist/* || true
          tar -zcf ../gptqmodel_source.tar.gz ./
          mv ../gptqmodel_source.tar.gz dist/
          sha256=$(sha256sum dist/gptqmodel_source.tar.gz)
          echo "hash=$sha256"
          echo "SOURCE_HASH=$sha256" >> $GITHUB_ENV
      

      #      - name: Upload source to local
      #        continue-on-error: true
      #        run: |
      ##         curl -s -F "runid=${{ github.run_id }}" -F "repo=${{ env.repo }}" -F "ref=${{ env.ref }}" -F "sha256=${{ env.SOURCE_HASH }}" -F "file=@dist/gptqmodel_source.tar.gz" http://$RUNNER/gpu2/whl/upload
      #          DIR=/opt/dist/${{ needs.check-vm.outputs.run_id }}
      #          [ -d $DIR ] || mkdir -p $DIR
      #          cp dist/gptqmodel_source.tar.gz $DIR/

      - name: Upload source to github artifact
        uses: actions/upload-artifact@v6
        with:
          name: source
          path: dist/gptqmodel_source.tar.gz

      - name: Compile
        if: github.event.inputs.artifact_id == '' && !cancelled()
        timeout-minutes: 45
        run: |
          set -euo pipefail
          
          echo "::group::python version"
          which python
          which pip || true
          python --version
          echo "::endgroup::"
          
          build_once() {
            echo "::group::compile logs"
            python setup.py bdist_wheel 2>&1 | tee /tmp/build.log
            echo "::endgroup::"
          }
          
          echo "==> Attempt #1 (no extra env)"
          if build_once; then
            echo "Build succeeded on attempt #1"
            exit 0
          fi
          
          echo "==> Attempt #1 failed, retrying with env vars..."
          export VERBOSE=1
          export CMAKE_VERBOSE_MAKEFILE=ON
          export TORCH_EXTENSIONS_DIR=/tmp/torch_extensions
          export MAX_JOBS=1
          export NVCC_THREADS=1
          
          echo "==> Attempt #2 (with env)"
          build_once

      - name: check wheel
        if: github.event.inputs.artifact_id == '' && !cancelled()
        run: |
          grep -nE "ptxas fatal|nvcc fatal|error:|fatal error|ninja: build stopped" /tmp/build.log | head -n 50
          
          echo "::group::compile logs"
          cat /tmp/build.log
          echo "::endgroup::"
          
          ls -ahl dist
          whl=$(ls -t dist/*.whl | head -n 1 | xargs basename)
          sha256=$(sha256sum dist/$whl)
          echo "hash=$sha256"

          echo "WHL_HASH=$sha256" >> $GITHUB_ENV
          echo "WHL_NAME=$whl" >> $GITHUB_ENV

          twine check dist/$whl
          [ $(stat -c%s "dist/$whl") -lt 104857600 ] && echo "wheel size < 100M" && exit 1 || echo "$whl size check passed."

      - name: Upload wheel to local
        if: github.event.inputs.artifact_id == '' && !cancelled()
        continue-on-error: true
        run: |
          WHEEL="$(readlink -f dist/*.whl)"
          SHA256="$(sha256sum "$WHEEL" | awk '{print $1}')"

          DIR=/opt/dist/${{ needs.check-vm.outputs.run_id }}
          [ -d $DIR ] || mkdir -p $DIR
          cp $WHEEL $DIR/

      - name: Upload wheel to github artifact
        if: github.event.inputs.artifact_id == '' && !cancelled()
        uses: actions/upload-artifact@v6
        with:
          name: whl
          path: dist/${{ env.WHL_NAME }}

      - name: Clean cache
        if: always()
        run: rm -rf ./* .[^.] .??* # pip cache purge && uv cache clean &&

  torch:
    needs:
      - build
      - list-test-files
      - check-vm
    runs-on: [ self-hosted, xeon5 ]
    container:
      image: ${{ needs.check-vm.outputs.ip }}:5000/nvidia/cuda:${{ needs.check-vm.outputs.cuda_version }}-ubuntu22.04_0206
      options: --device /dev/dri --ipc=host --runtime=nvidia --gpus all
      volumes:
        - /monster/ci/env/entrypoint.sh:/entrypoint.sh
        - /monster/ci/env/entrypoint.sh:/etc/profile.d/01-entrypoint.sh
        - /dev/dri/by-path:/dev/dri/by-path
        - /monster/ci/models:/monster/data/model
        - /monster/ci/dataset:/monster/data/model/dataset
        - /monster/ci/huggingface:/github/home/.cache/huggingface
        - /monster/ci/uv:/opt/uv
        - /monster/ci/env:/opt/env
        - /monster/ci/dist:/opt/dist
    strategy:
      fail-fast: false
      max-parallel: ${{ fromJson(needs.check-vm.outputs['max-parallel']).size || 20 }}
      matrix:
        test_script: ${{ fromJSON(needs.list-test-files.outputs.torch-files) }}
    if: always() && !cancelled() && (needs.build.result == 'success') && needs.list-test-files.outputs.torch-files != '[]' #  || github.event.inputs.artifact_id != ''
    steps:
      - name: Checkout Codes
        uses: actions/checkout@v6
        with:
          repository: ${{ env.repo }}
          ref: ${{ env.ref }}

      - name: Fetch PR by number
        if: ${{ github.event.inputs.pr_number != 0 }}
        run: |
          PR_NUMBER=${{ github.event.inputs.pr_number }}
          echo "pr number $PR_NUMBER"
          git config --global --add safe.directory $(pwd)
          git fetch origin pull/${PR_NUMBER}/head:pr-${PR_NUMBER}
          git checkout pr-${PR_NUMBER}

      - name: Print env
        run: |
          echo PATH=$PATH
          echo UV_INSTALL_DIR=$UV_INSTALL_DIR
          echo UV_PYTHON_BIN_DIR=$UV_PYTHON_BIN_DIR
          echo UV_PYTHON_INSTALL_DIR=$UV_PYTHON_INSTALL_DIR
          echo UV_PYTHON_CACHE_DIR=$UV_PYTHON_CACHE_DIR
          echo UV_CACHE_DIR=$UV_CACHE_DIR
          echo VENV_ROOT=$VENV_ROOT
          ls /root -ahl

      - name: Activate uv env
        run: |
          env_name="cu${{ needs.check-vm.outputs.cuda_version }}_torch${{ env.TORCH_VERSION }}_py${{ env.PYTHON_VERSION }}_test_${{ matrix.test_script }}"
          /opt/uv/setup_uv_venv.sh $env_name

      - name: Setup uv env
        run: |
          python -V
          which python
          which pip || true

          echo "setting env... cuda=${{ needs.check-vm.outputs.cuda_version }} torch=${{ env.TORCH_VERSION }} python=${{ env.PYTHON_VERSION }}"
          bash /opt/env/init_compiler_no_env.sh ${{ needs.check-vm.outputs.cuda_version }} ${{ env.TORCH_VERSION }} ${{ env.PYTHON_VERSION }}

      - name: Print uv env
        run: |
          echo "::group::uv python list"
          uv python list
          ls -ahl /opt/uv/venvs
          echo "::endgroup::"
          
          which python
          which pip || true
          python -V

          echo "::group::uv python list"
          uv python list
          echo "::endgroup::"

          echo "== nvcc =="
          nvcc --version

          echo "::group::pip list"
          uv pip list
          echo "::endgroup::"

          echo "== torch =="
          uv pip show torch || true

          echo "::group::project files"
          ls -ahl
          echo "::endgroup::"

          echo "== torch =="
          uv pip show torch

      #      - name: Install requirements
      #        run: |
      #          bash -c "$(curl -L http://${RUNNER}/scripts/env/init_compiler_no_env.sh)" @ ${{ needs.check-vm.outputs.cuda_version }} ${{ env.TORCH_VERSION }} $python_version${{ env.PYTHON_VERSION }}

      #      - name: Download source from local
      #        continue-on-error: true
      #        run: |
      #          curl -s -O  http://$RUNNER/whl/${{ env.repo }}/${{ github.run_id }}/gptqmodel_source.tar.gz
      #          ls -ahl .
      #          sha256=$(sha256sum $file_name)
      #          echo "sha256=$sha256"
      #          echo "SOURCE_DOWNLOADED=1" >> $GITHUB_ENV

      # - name: Download source from github
      #   if: env.SOURCE_DOWNLOADED == '' && !cancelled()
      #   uses: actions/download-artifact@v7
      #   with:
      #     name: source
      #     path: dist
      #     run-id: ${{ github.run_id }}

      #     - name: Uncompress source
      #      continue-on-error: true
      #     run: |
      #      find . -mindepth 1 ! -name "gptqmodel_source.tar.gz" -exec rm -rf {} +
      #     ls -ahl .
      #    tar -zxf gptqmodel_source.tar.gz

      - name: Download wheel from local
        continue-on-error: true
        run: |
          DIR=/opt/dist/${{ needs.check-vm.outputs.run_id }}
          [ -d $DIR ] || exit 1
          echo "WHL_DOWNLOADED=1" >> $GITHUB_ENV

          ls -ahl $DIR
          
          mkdir dist || true

          cp $DIR/*.whl dist/

      #          file_name=$(curl -s  -F "runid=${{ needs.check-vm.outputs.run_id }}" -F "repo=${{ env.repo }}" -F "ref=${{ env.ref }}" -F "fuzz=1" "http://$RUNNER/gpu2/whl/download")

      #          echo "file_name=$file_name"
      #
      #          if echo "$file_name" | grep -q "gptqmodel"; then
      #              mkdir dist || true
      #              cd dist
      #              curl -s -O  http://$RUNNER/whl/${{ env.repo }}/${{ needs.check-vm.outputs.run_id }}/$file_name
      #              ls -ahl .
      #              sha256=$(sha256sum $file_name)
      #              echo "sha256=$sha256"
      #              echo "WHL_DOWNLOADED=1" >> $GITHUB_ENV
      #          fi

      - name: Download artifact from github
        if: env.WHL_DOWNLOADED == '' && !cancelled()
        uses: actions/download-artifact@v7
        with:
          name: whl
          path: dist
          run-id: ${{ needs.check-vm.outputs.run_id }}

      - name: Install wheel
        run: |
          uv pip uninstall gptqmodel
          # make sure torch & torchvision are corresponded
          uv pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128
          uv pip install -r requirements.txt

          if [[ "${{ matrix.test_script }}" == *xpu* ]]; then
            echo "===== switching to xpu env ====="
            # source /etc/profile.d/pyenv.sh && pyenv activate xpu
          fi

          # ipex doesn't need to compile kernels. xpu can't install cuda package
          if [[ "${{ matrix.test_script }}" != *ipex* && "${{ matrix.test_script }}" != *xpu* ]]; then
            echo "===== install dist/whl ====="
            uv pip install dist/*.whl -i http://$RUNNER/simple/ --trusted-host $RUNNER --extra-index-url https://pypi.org/simple
          else
            echo "===== install with local files for xpu env ====="
            export CUDA_VISIBLE_DEVICES=""
            unset TORCH_CUDA_ARCH_LIST
            uv pip install . --no-build-isolation
          fi

          python .github/scripts/install_deps.py ${{ matrix.test_script }}
          # deps may reinstalled torch
          uv pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128

      - name: Find suitable GPU
        if: ${{ !contains(matrix.test_script, 'ipex') && !contains(matrix.test_script, 'xpu') && !cancelled() }}
        run: |
          set -Eeuo pipefail
          
          # -------------------- Configuration --------------------
          BASE_URL="http://${XEON5}"
          RUN_ID="${{ github.run_id }}"
          TEST="${{ matrix.test_script }}"
          RUNNER="${RUNNER_NAME:-unknown}"
          EXCLUSIVE="${{ github.event.inputs['exclusive-gpu'] }}"
          
          SLEEP_SEC=5
          TIMEOUT_SEC=18000   # Max wait time: 300 minutes
          # -------------------------------------------------------
          
          # URL encode helper to avoid breaking query parameters
          urlencode(){ python -c 'import sys,urllib.parse;print(urllib.parse.quote(sys.argv[1],""))' "$1"; }
          
          test_q=$(urlencode "$TEST")
          runner_q=$(urlencode "$RUNNER")
          exclusive_q=$(urlencode "$EXCLUSIVE")
          
          start_s=$(date +%s)
          gpu_id=""
          
          echo "Requesting GPU from allocator"
          echo "run_id=$RUN_ID test=$TEST runner=$RUNNER exclusive=$EXCLUSIVE"
          
          while true; do
            # Refresh timestamp every request to avoid cache or duplicated requests
            ts_ms=$(date +%s%3N)
            url="$BASE_URL/gpu2/get?runid=$RUN_ID&timestamp=$ts_ms&test=$test_q&runner=$runner_q&exclusive=$exclusive_q"
            echo "requesting GPU with: $url"
          
            # Call allocator
            # - May return:
            #   * integer >= 0  : allocated GPU ID
            #   * integer < 0   : no GPU available yet
            #   * empty / HTML : temporary server / proxy error
            resp="$(
              curl -fsS --connect-timeout 3 --max-time 10 \
                   --retry 3 --retry-delay 1 --retry-all-errors \
                   "$url" 2>/dev/null || true
            )"
          
            echo "resp={$resp}"
          
            # Normalize response
            resp="${resp//$'\r'/}"
            resp="${resp//$'\n'/}"
          
            # If response is empty or not an integer, treat as temporary error
            if [[ -z "$resp" || ! "$resp" =~ ^-?[0-9]+$ ]]; then
              echo "Allocator returned invalid response: '$resp' (temporary error)"
              curl -fsS "$BASE_URL/gpu2/status" || true
              sleep "$SLEEP_SEC"
              continue
            fi
          
            # Negative integer means no GPU available yet
            if (( resp < 0 )); then
              elapsed=$(( $(date +%s) - start_s ))
              if (( elapsed >= TIMEOUT_SEC )); then
                echo "Timed out after ${TIMEOUT_SEC}s waiting for GPU (last response=$resp)"
                curl -fsS "$BASE_URL/gpu2/status" || true
                exit 1
              fi
          
              echo "No GPU available (response=$resp). Waiting ${SLEEP_SEC}s... elapsed=${elapsed}s"
              curl -fsS "$BASE_URL/gpu2/status" || true
              sleep "$SLEEP_SEC"
              continue
            fi
          
            # Successful allocation
            gpu_id="$resp"
            echo "Allocated GPU ID: $gpu_id"
            break
          done
          
          # Export environment variables for subsequent steps
          echo "CUDA_VISIBLE_DEVICES=$gpu_id" >> "$GITHUB_ENV"
          echo "STEP_TIMESTAMP=$(date +%s%3N)" >> "$GITHUB_ENV"
          echo "CUDA_VISIBLE_DEVICES set to $gpu_id"
          
          # Final status snapshot
          curl -fsS "$BASE_URL/gpu2/status" || true


      - name: Run tests
        if: ${{ (!github.event.inputs.test_names || contains(github.event.inputs.test_names, matrix.test_script)) && !cancelled() }}
        run: |
          if [[ "${{ matrix.test_script }}" == *ipex* ]]; then
            export CUDA_VISIBLE_DEVICES=""
          fi
          if [[ "${{ matrix.test_script }}" == *xpu* ]]; then
            export CUDA_VISIBLE_DEVICES=""
            # source /etc/profile.d/pyenv.sh && pyenv activate xpu
            uv pip uninstall vllm -y
            uv pip list
          fi

          start_time=$(date +%s)
          pytest --durations=0 tests/${{ matrix.test_script }}.py || { echo "ERROR=1" >> $GITHUB_ENV; exit 1; }
          execution_time=$(( $(date +%s) - start_time ))
          echo "$((execution_time / 60))m $((execution_time % 60))s"
          curl "http://$XEON5/gpu2/log_test_vram?id=${{ github.run_id }}&gpu=${{ env.CUDA_VISIBLE_DEVICES }}&range=$execution_time&unit=second&test=${{ matrix.test_script }}"

      - name: Release GPU
        if: always() && !contains(matrix.test_script, 'ipex') && !contains(matrix.test_script, 'xpu')
        run: |
          resp=$(curl -s -X GET "http://$RUNNER/gpu2/release?id=${{ github.run_id }}&gpu=${{ env.CUDA_VISIBLE_DEVICES }}&timestamp=${{ env.STEP_TIMESTAMP }}&test=${{ matrix.test_script }}&runner=${RUNNER_NAME}")

          echo "response: $resp"
          if [ "$resp" != "${{ env.CUDA_VISIBLE_DEVICES }}" ]; then
            echo "Error: response ($resp) != expected (${{ env.CUDA_VISIBLE_DEVICES }})"
            exit 1
          fi

      - name: Clean cache
        if: always()
        run: |
          # rm ~/.cache/evalplus/*pkl || true
          # pip cache purge && uv cache clean
          rm -rf rm -rf ./* .[^.] .??*

#  show-statistics:
#    runs-on: [ self-hosted, xeon5 ]
#    if: always() && inputs['exclusive-gpu'] && !cancelled()
#    container:
#      image: modelcloud/gptqmodel:alpine-ci-v1
#    needs:
#      - torch
#    steps:
#      - name: Print statistics
#        run: curl "http://$RUNNER/gpu2/get_vram_logs?id=${{ github.run_id }}"

#  m4:
#    runs-on: [ self-hosted, m4 ]
#    needs:
#      - check-vm
#      - list-test-files
#    if: false && (github.event.inputs.test_names == '' || contains(github.event.inputs.test_names, 'apple') || contains(github.event.inputs.test_names, 'mlx') )  && (needs.list-test-files.outputs.m4-files != '' && needs.list-test-files.outputs.m4-files != '[]') && !cancelled()
#    strategy:
#      fail-fast: false
#      matrix:
#        test_script: ${{ fromJSON(needs.list-test-files.outputs.m4-files) }}
#    steps:
#      - name: Print Env
#        run: |
#          echo "repo: ${{ env.repo }}"
#          echo "ref: ${{ env.ref }}"
#          ls -ahl .
#
#      - name: Checkout Codes
#        uses: actions/checkout@v6
#        with:
#          repository: ${{ env.repo }}
#          ref: ${{ env.ref }}
#
#      - name: Run test
#        run: |
#          export PATH="/opt/homebrew/bin:$PATH" && eval "$(pyenv init -)"
#          rm -rf venv || true
#
#          echo "=== checking models dir is mounted"
#          ls ../../../monster
#
#          echo "=== activating venv"
#          pyenv global 3.11.11 && python -m venv venv
#          source venv/bin/activate
#
#          rm profile.sb || true
#
#          curl -O http://$RUNNER/scripts/m4/profile.sb
#
#          echo "=== installing uv setuptools build"
#          pip install setuptools build -U -i http://$RUNNER/simple --trusted-host $RUNNER --extra-index-url https://pypi.org/simple
#
#          echo "=== installing test tools"
#          uv pip install pytest parameterized vllm lm-eval device-smi mlx-lm -U -i http://$RUNNER/simple/ --trusted-host $RUNNER --extra-index-url https://pypi.org/simple
#
#          echo "=== installing gptqmodel"
#          uv pip install . --no-build-isolation -i http://$RUNNER/simple/ --trusted-host $RUNNER --extra-index-url https://pypi.org/simple
#
#          echo "replacing model path"
#          find tests -name "*.py" -exec sed -i '' 's/\/monster\/data\/model/..\/..\/..\/monster/g' {} +
#
#          TEST=${{ matrix.test_script }}
#          if [[ ! "$TEST" == *.py ]]; then
#          TEST="$TEST.py"
#          fi
#          echo "=== running test: $TEST"
#          pytest tests/$TEST
#
#      - name: Clean cache
#        if: always()
#        run: |
#          source venv/bin/activate && pip cache purge && uv cache clean || true
#          rm -rf ../GPTQModel && mkdir ../GPTQModel
#
#  mac-test:
#    runs-on: macos-latest
#    env:
#      CUDA_VISIBLE_DEVICES: ''
#      TORCH_CUDA_ARCH_LIST: ''
#      MAX_JOBS: 3
#      BUILD_QQQ: 0
#      BUILD_EORA: 0
#      GPTQMODEL_BUILD_EXLLAMA_V1: 0
#      GPTQMODEL_BUILD_EORA: 0
#      GPTQMODEL_FORCE_BUILD: 0
#    steps:
#      - name: Checkout Codes
#        uses: actions/checkout@v6
#
#      - uses: actions/setup-python@v6
#        with:
#          python-version: 3.12
#          cache: 'pip'
#
##       it wastes too much time to find which exactly one caused installation failed, just unset them all.....
#      - name: Install dependencies
#        run: |
#          unset CUDA_DEVICE_ORDER
#          unset CUDA_VISIBLE_DEVICES
#          unset TORCH_CUDA_ARCH_LIST
#          unset PYTORCH_ALLOC_CONF
#          unset MAX_JOBS
#          unset RUNNER
#          unset XEON5
#          unset UV_INDEX_URL
#          unset CUDA_VERSION
#          unset TORCH_VERSION
#          unset PYTHON_VERSION
#          unset # PYTHON_GIL
#          unset BUILD_QQQ
#          unset BUILD_EORA
#          unset GPTQMODEL_BUILD_EXLLAMA_V1
#          unset GPTQMODEL_BUILD_EORA
#          unset LEGACY_TESTS
#          unset IGNORED_TEST_FILES
#          unset GPTQMODEL_FORCE_BUILD
#          unset repo
#          unset ref
#
#          python -V
#          python -m venv venv
#          source venv/bin/activate
#          pip install pip uv setuptools build wheel torch -U
#          pip install meson-python -U
#          pip install numpy==2.2.6 -U
#
#          uv pip install -e . --no-build-isolation
#          pip install pip Pillow device_smi pypcre tokenicer threadpoolctl accelerate logbar transformers optimum torch -U
#
#      - name: Run test
#        run: |
#          source venv/bin/activate
#          python - <<'PY'
#          import os
#          from transformers import pipeline
#          os.environ["CUDA_VISIBLE_DEVICES"] = ""
#          os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
#          llm_pipeline = pipeline(model="JunHowie/Qwen3-0.6B-GPTQ-Int4")
#          output = llm_pipeline("Which city is the capital of France?", max_new_tokens=100)
#          print(output)
#
#          assert "paris" in output.lower()
#          PY
